<!doctype html> <html lang=en> <head> <meta charset=utf-8> <meta content="width=device-width,initial-scale=1" name=viewport> <meta content=#333333 name=theme-color> <base href=/ > <title>SIML</title> <link href=manifest.json rel=manifest crossorigin=use-credentials> <link href=favicon.png rel=icon type=image/png> <link href=https://cdn.jsdelivr.net/npm/bootstrap-icons@1.4.0/font/bootstrap-icons.css rel=stylesheet> <script>__SAPPER__={baseUrl:"",preloaded:[void 0,{}]};var s=document.createElement("script");try{new Function("if(0)import('')")();s.src="/client/client.af2bcc45.js";s.type="module";s.crossOrigin="use-credentials";}catch(e){s.src="/client/shimport@2.0.5.js";s.setAttribute("data-main","/client/client.af2bcc45.js")}document.head.appendChild(s)</script> <link href=client/client-5184f6d9.css rel=stylesheet><link href=client/publication-f8210d09.css rel=stylesheet> <style>body{margin:0;padding:0}</style> <link href=/client/client.af2bcc45.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/client-5184f6d9.css rel=preload as=style><link href=/client/publication.320f9885.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/inject_styles.5607aec6.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/publication-f8210d09.css rel=preload as=style></head> <body id=sapper> <header class=svelte-bhq2yl><div class="svelte-bhq2yl content"><a class="svelte-bhq2yl brand" href=home>SIML</a> <div class="svelte-bhq2yl nav"><a class=svelte-bhq2yl href=/home>Home</a> <a class="svelte-bhq2yl current" href=/publication>Publication</a> <a class=svelte-bhq2yl href=/people>People</a></div></div></header> <main class=svelte-8dulxs><div class="svelte-8dulxs content"> <div><h3 class=svelte-8dulxs>Preprints</h3> <div class="svelte-8dulxs list"><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/2006.10968 target=_blank>The Normal-Generalised Gamma-Pareto process: A novel pure-jump Lévy process with flexible tail and jump-activity properties</a></b> <p class=svelte-1t18id5>Fadhel Ayed, <b>Juho Lee</b>, François Caron</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>arXiv:2006.10968 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/1909.13433 target=_blank>Deep amortized clustering</a></b> <p class=svelte-1t18id5><b>Juho Lee</b>, Yoonho Lee, Yee Whye Teh</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>arXiv:1909.13433 </p> <p class=svelte-1t18id5>A preliminary version of this work has been accepted to NeurIPS 2019 Sets & Partitions workshop as an oral presentation.</p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/1905.10733 target=_blank>A unified construction for series representations and finite approximations of completely random measures</a></b> <p class=svelte-1t18id5><b>Juho Lee</b>, Xenia Miscouridou, François Caron</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>arXiv:1905.10733 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/1805.10896v3 target=_blank>Adaptive network sparsification with dependent variational beta-Bernoulli dropout</a></b> <p class=svelte-1t18id5><b>Juho Lee</b>, Saehoon Kim, Jaehong Yoon, Hae Beom Lee, Eunho Yang, Sung Ju Hwang</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>arXiv:1805.10896 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article></div></div> <div><h3 class=svelte-8dulxs>Conferences</h3> <div class="svelte-8dulxs list"><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/2107.01408 target=_blank>Scale Mixtures of Neural Network Gaussian Processes</a></b> <p class=svelte-1t18id5><b>Hyungi Lee</b>, <b>Eunggu Yun</b>, Hongseok Yang, <b>Juho Lee</b></p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>ICLR 2022 (To appear)</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/2110.02600 target=_blank>Sequential Reptile: inter-task gradient alignment for multilingual learning</a></b> <p class=svelte-1t18id5>Seanie Lee, Hae Beom Lee, <b>Juho Lee</b>, Sung Ju Hwang</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>ICLR 2022 (To appear)</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/2110.06381 target=_blank>Meta learning low rank covariance factors for energy-based deterministic uncertainty</a></b> <p class=svelte-1t18id5>Jeffrey Ryan Willette, Hae Beom Lee, <b>Juho Lee</b>, Sung Ju Hwang</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>ICLR 2022 (To appear)</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/2110.14149 target=_blank>Diversity matters when learning from ensembles</a></b> <p class=svelte-1t18id5><b>Giung Nam</b>*, <b>Jongmin Yoon</b>*, Yoonho Lee, <b>Juho Lee</b></p> <p class=svelte-1t18id5>(*: Equal Contribution)</p> <p class=svelte-1t18id5>NeurIPS 2021 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5><b class=code><a class=svelte-1t18id5 href=https://github.com/cs-giung/giung2/tree/main/projects/Diversity-Matters target=_blank>Code</a></b></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/2103.01615 target=_blank>Mini-batch consistent slot set encoder for scalable set encoding</a></b> <p class=svelte-1t18id5>Andreis Bruno, Jeffrey Ryan Willette, <b>Juho Lee</b>, Sung Ju Hwang</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>NeurIPS 2021 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://openaccess.thecvf.com/content/ICCV2021/html/Liu_A_Multi-Mode_Modulator_for_Multi-Domain_Few-Shot_Classification_ICCV_2021_paper.html target=_blank>A multi-mode modulator for multi-domain few-shot classification</a></b> <p class=svelte-1t18id5>Yanbin Liu, <b>Juho Lee</b>, Linchao Zhu, Ling Chen, Humphrey Shi, Yi Yang</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>ICCV 2021 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5><b class=code><a class=svelte-1t18id5 href=https://github.com/csyanbin/tri-M-ICCV target=_blank>Code</a></b></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/2106.06041 target=_blank>Adversarial purification with score-based generative models</a></b> <p class=svelte-1t18id5><b>Jongmin Yoon</b>, Sung Ju Hwang, <b>Juho Lee</b></p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>ICML 2021 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5><b class=code><a class=svelte-1t18id5 href=https://github.com/jmyoon1/adp target=_blank>Code</a></b></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/2105.02692 target=_blank>Learning to perturb word embeddings for out-of-distribution QA</a></b> <p class=svelte-1t18id5>Seanie Lee, Minki Kang, <b>Juho Lee</b>, Sung Ju Hwang</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>ACL 2021 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/2103.15619 target=_blank>SetVAE: learning hierarchical composition for generative modeling of set-structured data</a></b> <p class=svelte-1t18id5>Jinwoo Kim, Jaehoon Yoo, <b>Juho Lee</b>, Seunghoon Hong</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>CVPR 2021 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5><b class=code><a class=svelte-1t18id5 href=https://github.com/jw9730/setvae target=_blank>Code</a></b></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/2008.02956 target=_blank>Bootstrapping neural processes</a></b> <p class=svelte-1t18id5><b>Juho Lee</b>*, Yoonho Lee*, Jungtaek Kim, Eunho Yang, Sung Ju Hwang, Yee Whye Teh</p> <p class=svelte-1t18id5>(*: Equal Contribution)</p> <p class=svelte-1t18id5>NeurIPS 2020 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5><b class=code><a class=svelte-1t18id5 href=https://github.com/juho-lee/bnp target=_blank>Code</a></b></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/2008.02953 target=_blank>Neural complexity measures</a></b> <p class=svelte-1t18id5>Yoonho Lee, <b>Juho Lee</b>, Sung Ju Hwang, Eunho Yang, Seungjin Choi</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>NeurIPS 2020 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5><b class=code><a class=svelte-1t18id5 href=https://github.com/yoonholee/neural-complexity target=_blank>Code</a></b></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/2006.05419 target=_blank>Cost-effective interactive attention learning with neural attention processes</a></b> <p class=svelte-1t18id5>Jay Heo, Junhyeon Park, Hyewon Jeong, Kwang Joon Kim, <b>Juho Lee</b>, Eunho Yang, Sung Ju Hwang</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>ICML 2020 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/1806.01551 target=_blank>Deep mixed effect model using Gaussian processes: a personalized and reliable prediction for healthcare</a></b> <p class=svelte-1t18id5>Ingyo Chung, Saehoon Kim, <b>Juho Lee</b>, Sung Ju Hwang, Eunho Yang</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>AAAI 2020 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/1902.04714 target=_blank>Beyond the Chinese restaurant and Pitman-Yor processes: statistical models with double power-law behavior</a></b> <p class=svelte-1t18id5>Fadhel Ayed*, <b>Juho Lee</b>*, François Caron</p> <p class=svelte-1t18id5>(*: Equal Contribution)</p> <p class=svelte-1t18id5>ICML 2019 (full oral presentation)</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/1810.00825v3 target=_blank>Set transformer: a framework for attention-based permutation-invariant neural networks</a></b> <p class=svelte-1t18id5><b>Juho Lee</b>, Yoonho Lee, Jungtaek Kim, Adam R. Kosiorek, Seungjin Choi, Yee Whye Teh</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>ICML 2019 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5><b class=code><a class=svelte-1t18id5 href=https://github.com/juho-lee/set_transformer target=_blank>Code</a></b></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/1805.10002 target=_blank>Learning to propagate labels: transductive propagation network for few-shot learning</a></b> <p class=svelte-1t18id5>Yanbin Liu, <b>Juho Lee</b>, Minseop Park, Saehoon Kim, Eunho Yang, Sung Ju Hwang, Yi Yang</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>ICLR 2019 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/1810.01778 target=_blank>A Bayesian model for sparse graphs with flexible degree distribution and overlapping community structure</a></b> <p class=svelte-1t18id5><b>Juho Lee</b>, Lancelot F. James, Seungjin Choi, François Caron</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>AISTATS 2019 (oral presentation)</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5><b class=code><a class=svelte-1t18id5 href=https://github.com/OxCSML-BayesNP/BNRG target=_blank>Code</a></b></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/1805.09653 target=_blank>Uncertainty-aware attention for reliable interpretation and prediction</a></b> <p class=svelte-1t18id5>Jay Heo*, Hae Beom Lee*, Saehoon Kim, <b>Juho Lee</b>, Kwang Joon Kim, Eunho Yang, Sung Ju Hwang</p> <p class=svelte-1t18id5>(*: Equal Contribution)</p> <p class=svelte-1t18id5>NeurIPS 2018 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://arxiv.org/abs/1712.07834 target=_blank>Dropmax: adaptive variational softmax</a></b> <p class=svelte-1t18id5>Hae Beom Lee, <b>Juho Lee</b>, Saehoon Kim, Eunho Yang, Sung Ju Hwang</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>NeurIPS 2018 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5><b class=code><a class=svelte-1t18id5 href=https://github.com/haebeom-lee/dropmax target=_blank>Code</a></b></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=http://proceedings.mlr.press/v70/lee17a.html target=_blank>Bayesian inference on random simple graphs with power law degree distributions</a></b> <p class=svelte-1t18id5><b>Juho Lee</b>, Creighton Heakulani, Zoubin Ghahramani, Lancelot F. James, Seingjin Choi</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>ICML 2017 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5><b class=code><a class=svelte-1t18id5 href=https://github.com/juho-lee/powerlawgraph target=_blank>Code</a></b></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://papers.nips.cc/paper/6348-finite-dimensional-bfry-priors-and-variational-bayesian-inference-for-power-law-models target=_blank>Finite-dimensional BFRY priors and variational Bayesian inference for power law models</a></b> <p class=svelte-1t18id5><b>Juho Lee</b>, Lancelot F. James, Seungjin Choi</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>NIPS 2016 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://papers.nips.cc/paper/5800-tree-guided-mcmc-inference-for-normalized-random-measure-mixture-models target=_blank>Tree-guided MCMC inference for normalized random measure mixture models</a></b> <p class=svelte-1t18id5><b>Juho Lee</b>, Seungjin Choi</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>NIPS 2015 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5><b class=code><a class=svelte-1t18id5 href=https://github.com/juho-lee/nrmm.cpp target=_blank>Code</a></b></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=http://proceedings.mlr.press/v38/lee15c.html target=_blank>Bayesian hierarchical clustering with exponential family: small-variance asymptotics and reducibility</a></b> <p class=svelte-1t18id5><b>Juho Lee</b>, Seungjin Choi</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>AISTATS 2015 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=http://proceedings.mlr.press/v33/lee14.html target=_blank>Incremental tree-based inference with dependent normalized random measures</a></b> <p class=svelte-1t18id5><b>Juho Lee</b>, Seungjin Choi</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>AISTATS 2014 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article><article class=svelte-1t18id5> <section class=svelte-1t18id5><b class=title><a class=svelte-1t18id5 href=https://link.springer.com/chapter/10.1007/978-3-642-33765-9_61 target=_blank>Online video segmentation by Bayesian split-merge clustering</a></b> <p class=svelte-1t18id5><b>Juho Lee</b>, Suha Kwak, Bohyung Han, Seungjin Choi</p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5>ECCV 2012 </p> <p class=svelte-1t18id5></p> <p class=svelte-1t18id5></section></article></div></div></div></main> <footer class=svelte-i1cmow><div class="svelte-i1cmow content"><p class="svelte-i1cmow justify-left"><a class=svelte-i1cmow href=https://goo.gl/maps/mga73qU9oT8Bhz8D6><i class="bi bi-geo-alt"></i> KAIST N5 2225 </a></div></footer> <script src=bootstrap.bundle.min.js></script> 