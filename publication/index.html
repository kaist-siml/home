<!doctype html> <html lang=en> <head> <meta charset=utf-8> <meta content="width=device-width,initial-scale=1" name=viewport> <meta content=#004191 name=theme-color> <base href=/ > <link href=fonts.css rel=stylesheet> <link href=manifest.json rel=manifest> <link href=favicon.png rel=icon type=image/png> <link href=https://cdn.jsdelivr.net/npm/bootstrap-icons@1.4.0/font/bootstrap-icons.css rel=stylesheet> <link href=client/client-6a7065fa.css rel=stylesheet><link href=client/publication-d1dd5d57.css rel=stylesheet> <title>SIML - Publication</title> <link href=/client/client.83704724.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/client-6a7065fa.css rel=preload as=style><link href=/client/publication.8e0c9c58.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/inject_styles.803b7e80.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/publication-d1dd5d57.css rel=preload as=style></head> <body id=sapper> <header class=svelte-10v0hvd><div class="svelte-10v0hvd content"><a class="svelte-10v0hvd brand" href=/ >SIML</a> <nav class=svelte-10v0hvd><a class=svelte-10v0hvd href=.>home</a> <a class=svelte-10v0hvd href=research>research</a> <a class="svelte-10v0hvd selected" href=publication>publication</a> <a class=svelte-10v0hvd href=people>people</a></nav></div></header> <main><div class="svelte-191hpda container"><h2 class=svelte-191hpda>Journals</h2> <ul class=svelte-191hpda><li class=svelte-191hpda><a class=svelte-191hpda target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>The Normal-Generalised Gamma-Pareto process: A novel pure-jump Lévy process with flexible tail and jump-activity properties</b></p> <p class=svelte-191hpda>Fadhel Ayed, Juho Lee, François Caron</p> <p class=svelte-191hpda>To appear in Bayesian Anaylsis</p> <p class=svelte-191hpda><b></b></p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2006.10968 target=_blank>preprint</a> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>A unified construction for series representations and finite approximations of completely random measures</b></p> <p class=svelte-191hpda>Juho Lee, Xenia Miscouridou, François Caron</p> <p class=svelte-191hpda>To appear in Bernoulli</p> <p class=svelte-191hpda><b></b></p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/1905.10733 target=_blank>preprint</a> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2021MS002921 target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Benefits of stochastic weight averaging in developing neural network radiation scheme for numerical weather prediction</b></p> <p class=svelte-191hpda>Hwan-Jin Song, Soonyoung Roh, Juho Lee, Giung Nam, Eunggu Yun, Jongmin Yoon, Park Sa Kim</p> <p class=svelte-191hpda>Journal of Advances in Modeling Earth Systems, October 2022</p> <p class=svelte-191hpda><b></b></p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://www.essoar.org/doi/abs/10.1002/essoar.10508964.2 target=_blank>preprint</a> </div> </a></ul> <h2 class=svelte-191hpda>Conferences</h2> <ul class=svelte-191hpda><li class=svelte-191hpda><a class=svelte-191hpda href="https://openreview.net/forum?id=-9PVqZ-IR_" target=_blank><img alt=... class=svelte-191hpda src=image/publication/C2023_05.png> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Martingale posterior neural processes</b></p> <p class=svelte-191hpda>Hyungi Lee, Eunggu Yun, Giung Nam, Edwin Fong, Juho Lee</p> <p class=svelte-191hpda>International Conference on Learning Representations (ICLR), 2023</p> <p class=svelte-191hpda> <b>Spotlight Presentation (notable-top-25%)</b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href="https://openreview.net/forum?id=bcYZwYo-0t" target=_blank><img alt=... class=svelte-191hpda src=image/publication/C2023_04.png> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Decoupled training for long-tailed classification with stochastic representations</b></p> <p class=svelte-191hpda>Giung Nam*, Sunguk Jang*, Juho Lee</p> <p class=svelte-191hpda>International Conference on Learning Representations (ICLR), 2023</p> <p class=svelte-191hpda> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href="https://openreview.net/forum?id=IVESH65r0Ar" target=_blank><img alt=... class=svelte-191hpda src=image/publication/C2023_03.png> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>A simple yet powerful deep active learning with snapshot ensembles</b></p> <p class=svelte-191hpda>Seohyeon Jung*, Sanghyun Kim*, Juho Lee</p> <p class=svelte-191hpda>International Conference on Learning Representations (ICLR), 2023</p> <p class=svelte-191hpda> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href="https://openreview.net/forum?id=kj6oK_Hj40" target=_blank><img alt=... class=svelte-191hpda src=image/publication/C2023_02.png> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Self-distillation for further pre-training of transformers</b></p> <p class=svelte-191hpda>Seanie Lee, Minki Kang, Juho Lee, Sung Ju Hwang, Kenji Kawaguchi</p> <p class=svelte-191hpda>International Conference on Learning Representations (ICLR), 2023</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2210.02871 target=_blank>preprint</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href="https://openreview.net/forum?id=7sn6Vxp92xV" target=_blank><img alt=... class=svelte-191hpda src=image/publication/C2023_01.png> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Exploring the role of mean teachers in self-supervised masked auto-encoders</b></p> <p class=svelte-191hpda>Youngwan Lee*, Jeffrey Ryan Willette*, Jonghee Kim, Juho Lee, Sung Ju Hwang</p> <p class=svelte-191hpda>International Conference on Learning Representations (ICLR), 2023</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2210.02077 target=_blank>preprint</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href="https://openreview.net/forum?id=bg7d_2jWv6" target=_blank><img alt=... class=svelte-191hpda src=image/publication/C2022_07.png> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>On divergence measures for Bayesian pseudocoresets</b></p> <p class=svelte-191hpda>Balhae Kim, Jungwon Choi, Seanie Lee, Yoonho Lee, Jung-Woo Ha, Juho Lee</p> <p class=svelte-191hpda>Neural Information Processing Systems (NeurIPS), 2022</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2210.06205 target=_blank>preprint</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href="https://openreview.net/forum?id=78T4K99jvbE" target=_blank><img alt=... class=svelte-191hpda src=image/publication/C2022_06.png> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Set-based meta-interpolation for few-task meta-learning</b></p> <p class=svelte-191hpda>Seanie Lee*, Bruno Andreis*, Kenji Kawaguchi, Juho Lee, Sung Ju Hwang</p> <p class=svelte-191hpda>Neural Information Processing Systems (NeurIPS), 2022</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2205.09990 target=_blank>preprint</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://proceedings.mlr.press/v162/nam22a.html target=_blank><img alt=... class=svelte-191hpda src=image/publication/C2022_05.png> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Improving ensemble distillation with weight averaging and diversifying perturbation</b></p> <p class=svelte-191hpda>Giung Nam, Hyungi Lee, Byeongho Heo, Juho Lee</p> <p class=svelte-191hpda>International Conference on Machine Learning (ICML), 2022</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2206.15047 target=_blank>preprint</a> <a class=svelte-191hpda href=https://github.com/cs-giung/distill-latentbe target=_blank>code</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://proceedings.mlr.press/v162/andreis22a.html target=_blank><img alt=... class=svelte-191hpda src=image/publication/C2022_04.png> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Set based stochastic subsampling</b></p> <p class=svelte-191hpda>Bruno Andreis, Seanie Lee, A. Tuan Nguyen, Juho Lee, Eunho Yang, Sung Ju Hwang</p> <p class=svelte-191hpda>International Conference on Machine Learning (ICML), 2022</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2006.14222 target=_blank>preprint</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href="https://openreview.net/forum?id=YVPBh4k78iZ" target=_blank><img alt=... class=svelte-191hpda src=image/publication/C2022_03.png> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Scale Mixtures of Neural Network Gaussian Processes</b></p> <p class=svelte-191hpda>Hyungi Lee, Eunggu Yun, Hongseok Yang, Juho Lee</p> <p class=svelte-191hpda>International Conference on Learning Representations (ICLR), 2022</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2107.01408 target=_blank>preprint</a> <a class=svelte-191hpda href=https://github.com/Hyungi-Lee/Scale-Mixtures-of-Neural-Network-Gaussian-Processes target=_blank>code</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href="https://openreview.net/forum?id=ivQruZvXxtz" target=_blank><img alt=... class=svelte-191hpda src=image/publication/C2022_02.png> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Sequential Reptile: inter-task gradient alignment for multilingual learning</b></p> <p class=svelte-191hpda>Seanie Lee*, Hae Beom Lee*, Juho Lee, Sung Ju Hwang</p> <p class=svelte-191hpda>International Conference on Learning Representations (ICLR), 2022</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2110.02600 target=_blank>preprint</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href="https://openreview.net/forum?id=GQd7mXSPua" target=_blank><img alt=... class=svelte-191hpda src=image/publication/C2022_01.png> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Meta learning low rank covariance factors for energy-based deterministic uncertainty</b></p> <p class=svelte-191hpda>Jeffrey Ryan Willette, Hae Beom Lee, Juho Lee, Sung Ju Hwang</p> <p class=svelte-191hpda>International Conference on Learning Representations (ICLR), 2022</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2110.06381 target=_blank>preprint</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://papers.nips.cc/paper/2021/hash/466473650870501e3600d9a1b4ee5d44-Abstract.html target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Diversity matters when learning from ensembles</b></p> <p class=svelte-191hpda>Giung Nam*, Jongmin Yoon*, Yoonho Lee, Juho Lee</p> <p class=svelte-191hpda>Neural Information Processing Systems (NeurIPS), 2021</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2110.14149 target=_blank>preprint</a> <a class=svelte-191hpda href=https://github.com/cs-giung/giung2/tree/main/projects/Diversity-Matters target=_blank>code</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://papers.nips.cc/paper/2021/hash/b24d516bb65a5a58079f0f3526c87c57-Abstract.html target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Mini-batch consistent slot set encoder for scalable set encoding</b></p> <p class=svelte-191hpda>Andreis Bruno, Jeffrey Ryan Willette, Juho Lee, Sung Ju Hwang</p> <p class=svelte-191hpda>Neural Information Processing Systems (NeurIPS), 2021</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2103.01615 target=_blank>preprint</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://openaccess.thecvf.com/content/ICCV2021/html/Liu_A_Multi-Mode_Modulator_for_Multi-Domain_Few-Shot_Classification_ICCV_2021_paper.html target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>A multi-mode modulator for multi-domain few-shot classification</b></p> <p class=svelte-191hpda>Yanbin Liu, Juho Lee, Linchao Zhu, Ling Chen, Humphrey Shi, Yi Yang</p> <p class=svelte-191hpda>International Conference on Computer Vision (ICCV), 2021</p> <p class=svelte-191hpda> <a class=svelte-191hpda href=https://github.com/csyanbin/tri-M-ICCV target=_blank>code</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://proceedings.mlr.press/v139/yoon21a.html target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Adversarial purification with score-based generative models</b></p> <p class=svelte-191hpda>Jongmin Yoon, Sung Ju Hwang, Juho Lee</p> <p class=svelte-191hpda>International Conference on Machine Learning (ICML), 2021</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2106.06041 target=_blank>preprint</a> <a class=svelte-191hpda href=https://github.com/jmyoon1/adp target=_blank>code</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://aclanthology.org/2021.acl-long.434/ target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Learning to perturb word embeddings for out-of-distribution QA</b></p> <p class=svelte-191hpda>Seanie Lee, Minki Kang, Juho Lee, Sung Ju Hwang</p> <p class=svelte-191hpda>Association for Computational Linguistics (ACL), 2021</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2105.02692 target=_blank>preprint</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://openaccess.thecvf.com/content/CVPR2021/html/Kim_SetVAE_Learning_Hierarchical_Composition_for_Generative_Modeling_of_Set-Structured_Data_CVPR_2021_paper.html target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>SetVAE: learning hierarchical composition for generative modeling of set-structured data</b></p> <p class=svelte-191hpda>Jinwoo Kim, Jaehoon Yoo, Juho Lee, Seunghoon Hong</p> <p class=svelte-191hpda>Conference on Computer Vision and Pattern Recognition (CVPR), 2021</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2103.15619 target=_blank>preprint</a> <a class=svelte-191hpda href=https://github.com/jw9730/setvae target=_blank>code</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://papers.nips.cc/paper/2020/hash/492114f6915a69aa3dd005aa4233ef51-Abstract.html target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Bootstrapping neural processes</b></p> <p class=svelte-191hpda>Juho Lee*, Yoonho Lee*, Jungtaek Kim, Eunho Yang, Sung Ju Hwang, Yee Whye Teh</p> <p class=svelte-191hpda>Neural Information Processing Systems (NeurIPS), 2020</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2008.02956 target=_blank>preprint</a> <a class=svelte-191hpda href=https://github.com/juho-lee/bnp target=_blank>code</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://papers.nips.cc/paper/2020/hash/6e17a5fd135fcaf4b49f2860c2474c7c-Abstract.html target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Neural complexity measures</b></p> <p class=svelte-191hpda>Yoonho Lee, Juho Lee, Sung Ju Hwang, Eunho Yang, Seungjin Choi</p> <p class=svelte-191hpda>Neural Information Processing Systems (NeurIPS), 2020</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2008.02953 target=_blank>preprint</a> <a class=svelte-191hpda href=https://github.com/yoonholee/neural-complexity target=_blank>code</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://proceedings.mlr.press/v119/heo20a.html target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Cost-effective interactive attention learning with neural attention processes</b></p> <p class=svelte-191hpda>Jay Heo, Junhyeon Park, Hyewon Jeong, Kwang Joon Kim, Juho Lee, Eunho Yang, Sung Ju Hwang</p> <p class=svelte-191hpda>International Conference on Machine Learning (ICML), 2020</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/2006.05419 target=_blank>preprint</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://ojs.aaai.org/index.php/AAAI/article/view/5773 target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Deep mixed effect model using Gaussian processes: a personalized and reliable prediction for healthcare</b></p> <p class=svelte-191hpda>Ingyo Chung, Saehoon Kim, Juho Lee, Sung Ju Hwang, Eunho Yang</p> <p class=svelte-191hpda>Association for the Advancement of Artificial Intelligence (AAAI), 2020</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/1806.01551 target=_blank>preprint</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://proceedings.mlr.press/v97/ayed19a.html target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Beyond the Chinese restaurant and Pitman-Yor processes: statistical models with double power-law behavior</b></p> <p class=svelte-191hpda>Fadhel Ayed*, Juho Lee*, François Caron</p> <p class=svelte-191hpda>International Conference on Machine Learning (ICML), 2019</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/1902.04714 target=_blank>preprint</a> <b>Long Oral Presentation</b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://github.com/juho-lee/set_transformer target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Set transformer: a framework for attention-based permutation-invariant neural networks</b></p> <p class=svelte-191hpda>Fadhel Ayed*, Juho Lee*, François Caron</p> <p class=svelte-191hpda>International Conference on Machine Learning (ICML), 2019</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/1810.00825 target=_blank>preprint</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href="https://openreview.net/forum?id=SyVuRiC5K7" target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Learning to propagate labels: transductive propagation network for few-shot learning</b></p> <p class=svelte-191hpda>Yanbin Liu, Juho Lee, Minseop Park, Saehoon Kim, Eunho Yang, Sung Ju Hwang, Yi Yang</p> <p class=svelte-191hpda>International Conference on Learning Representations (ICLR), 2019</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/1805.10002 target=_blank>preprint</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://proceedings.mlr.press/v89/lee19b.html target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>A Bayesian model for sparse graphs with flexible degree distribution and overlapping community structure</b></p> <p class=svelte-191hpda>Juho Lee, Lancelot F. James, Seungjin Choi, François Caron</p> <p class=svelte-191hpda>International Conference on Artificial Intelligence and Statistics (AISTATS), 2019</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/1810.01778 target=_blank>preprint</a> <a class=svelte-191hpda href=https://github.com/OxCSML-BayesNP/BNRG target=_blank>code</a> <b>Oral Presentation</b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://papers.nips.cc/paper/2018/hash/285e19f20beded7d215102b49d5c09a0-Abstract.html target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Uncertainty-aware attention for reliable interpretation and prediction</b></p> <p class=svelte-191hpda>Jay Heo*, Hae Beom Lee*, Saehoon Kim, Juho Lee, Kwang Joon Kim, Eunho Yang, Sung Ju Hwang</p> <p class=svelte-191hpda>Neural Information Processing Systems (NeurIPS), 2018</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/1805.09653 target=_blank>preprint</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://papers.nips.cc/paper/2018/hash/389bc7bb1e1c2a5e7e147703232a88f6-Abstract.html target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Dropmax: adaptive variational softmax</b></p> <p class=svelte-191hpda>Hae Beom Lee, Juho Lee, Saehoon Kim, Eunho Yang, Sung Ju Hwang</p> <p class=svelte-191hpda>Neural Information Processing Systems (NeurIPS), 2018</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/1712.07834 target=_blank>preprint</a> <a class=svelte-191hpda href=https://github.com/haebeom-lee/dropmax target=_blank>code</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=http://proceedings.mlr.press/v70/lee17a.html target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Bayesian inference on random simple graphs with power law degree distributions</b></p> <p class=svelte-191hpda>Juho Lee, Creighton Heakulani, Zoubin Ghahramani, Lancelot F. James, Seingjin Choi</p> <p class=svelte-191hpda>International Conference on Machine Learning (ICML), 2017</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/1702.08239 target=_blank>preprint</a> <a class=svelte-191hpda href=https://github.com/juho-lee/powerlawgraph target=_blank>code</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://papers.nips.cc/paper/6348-finite-dimensional-bfry-priors-and-variational-bayesian-inference-for-power-law-model target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Finite-dimensional BFRY priors and variational Bayesian inference for power law models</b></p> <p class=svelte-191hpda>Juho Lee, Lancelot F. James, Seungjin Choi</p> <p class=svelte-191hpda>Neural Information Processing Systems (NIPS; NeurIPS), 2016</p> <p class=svelte-191hpda> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://papers.nips.cc/paper/5800-tree-guided-mcmc-inference-for-normalized-random-measure-mixture-models target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Tree-guided MCMC inference for normalized random measure mixture models</b></p> <p class=svelte-191hpda>Juho Lee, Seungjin Choi</p> <p class=svelte-191hpda>Neural Information Processing Systems (NIPS; NeurIPS), 2015</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/1511.05650 target=_blank>preprint</a> <a class=svelte-191hpda href=https://github.com/juho-lee/nrmm.cpp target=_blank>code</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=http://proceedings.mlr.press/v38/lee15c.html target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Bayesian hierarchical clustering with exponential family: small-variance asymptotics and reducibility</b></p> <p class=svelte-191hpda>Juho Lee, Seungjin Choi</p> <p class=svelte-191hpda>International Conference on Artificial Intelligence and Statistics (AISTATS), 2015</p> <p class=svelte-191hpda><a class=svelte-191hpda href=https://arxiv.org/abs/1501.07430 target=_blank>preprint</a> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=http://proceedings.mlr.press/v33/lee14.html target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Incremental tree-based inference with dependent normalized random measures</b></p> <p class=svelte-191hpda>Juho Lee, Seungjin Choi</p> <p class=svelte-191hpda>International Conference on Artificial Intelligence and Statistics (AISTATS), 2014</p> <p class=svelte-191hpda> <b></b> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://link.springer.com/chapter/10.1007/978-3-642-33765-9_61 target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Online video segmentation by Bayesian split-merge clustering</b></p> <p class=svelte-191hpda>Juho Lee, Suha Kwak, Bohyung Han, Seungjin Choi</p> <p class=svelte-191hpda>European Conference on Computer Vision (ECCV), 2012</p> <p class=svelte-191hpda> <b></b> </div> </a></ul> <h2 class=svelte-191hpda>Workshops</h2> <ul class=svelte-191hpda><li class=svelte-191hpda><a class=svelte-191hpda href="https://openreview.net/forum?id=pKyB5wMnTiy" target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Modeling uplift from observational time-series in continual scenarios</b></p> <p class=svelte-191hpda>Sanghyun Kim, Jungwon Choi, NamHee Kim, Jaesung Ryu, Juho Lee</p> <p class=svelte-191hpda>AAAI-23 Bridge on Continual Casality, 2023</p> <p class=svelte-191hpda><b>Oral Presentation</b></p> <p class=svelte-191hpda> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href="https://openreview.net/forum?id=fuHh4CC3-5Z" target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Adaptive strategy for resetting a non-stationary Markov chain during learning via joint stochastic optimization</b></p> <p class=svelte-191hpda>Hyunsu Kim, Juho Lee, Hongseok Yang</p> <p class=svelte-191hpda>Third Symposium on Advances in Approximate Bayesian Inference, 2021</p> <p class=svelte-191hpda><b></b></p> <p class=svelte-191hpda> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://slideslive.com/38923511/contributed-talk-towards-deep-amortized-clustering target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Towards deep amortized clustering</b></p> <p class=svelte-191hpda>Juho Lee, Yoonho Lee, Yee Whye Teh</p> <p class=svelte-191hpda>NeurIPS 2019 Sets & Partitions workshop, 2019</p> <p class=svelte-191hpda><b>Contributed Talk</b></p> <p class=svelte-191hpda> </div> </a><li class=svelte-191hpda><a class=svelte-191hpda href=https://grlearning.github.io/papers/19.pdf target=_blank><img alt=... class=svelte-191hpda src=image/dummy_paper.svg> <div class="svelte-191hpda wrap"><p class=svelte-191hpda><b>Graph embedding VAE: a permutation invariant model of graph structure</b></p> <p class=svelte-191hpda>Tony Duan, Juho Lee</p> <p class=svelte-191hpda>NeurIPS 2019 Graph Representation Learning workshop, 2019</p> <p class=svelte-191hpda><b></b></p> <p class=svelte-191hpda> </div> </a></ul></div></main> <footer class=svelte-20p8do><div class="svelte-20p8do content"><p class="svelte-20p8do justify-left"><i class="bi bi-geo-alt"></i> <a class=svelte-20p8do href=https://goo.gl/maps/mga73qU9oT8Bhz8D6 target=_blank>KAIST N5, Room 2225 </a></div></footer> <script>__SAPPER__={baseUrl:"",preloaded:[void 0,{}]};if('serviceWorker' in navigator)navigator.serviceWorker.register('/service-worker.js');var s=document.createElement("script");try{new Function("if(0)import('')")();s.src="/client/client.83704724.js";s.type="module";s.crossOrigin="use-credentials";}catch(e){s.src="/client/shimport@2.0.5.js";s.setAttribute("data-main","/client/client.83704724.js")}document.head.appendChild(s)</script> <script src=bootstrap.bundle.min.js></script> 