import{S as e,i as a,s as n,e as t,t as s,a as i,b as r,f as l,g as o,d as c,c as d,j as h,m,k as g,l as u,n as p,q as f,o as v}from"./client.1e89ccf9.js";var y=[{name:"Bayesian Deep Learning",image:"image/dummy_wide.svg",description:"Modern deep neural networks are typically overparameterized and thus under-specified by the available data.\nIn other words, deep neural networks often contain multiple solutions which can express hypotheses describing the data.\nWhile the classical training of deep neural networks aims to find a single solution, the Bayesian approach considers multiple possible solutions by performing marginalization.\nWe are studying various sub-fields involving deep neural networks from the Bayesian perspective.\n"},{name:"Diffusion",image:"image/dummy_wide.svg",description:"WIP - Description here\n"},{name:"Meta-Learning",image:"image/research/meta-learning.png",description:"Meta-learning basically refers to a learning algorithm that learns how to learn, but more broadly it refers to any learning algorithm that learns meta-knowledge that helps other learning.\nMeta-learning is essential to creating human-like AI, such as being able to continuously learn or process multimodal data.\nIn our lab, we are interested in both the fundamentals and applications of meta-learning.\nFor example, we are interested in developing meta-learning algorithms and learning representations of meta-knowledge under real-world constraints, such as when there is only limited data.\nWe also develop meta-learning algorithms for various fields such as domain generalization, generative modeling, and Bayesian learning.\n"},{name:"Healthcare",image:"image/dummy_wide.svg",description:"Detecting cancer was doctorsâ€™ exclusive work before. Nowadays, thanks to the development of WSI(whole slide image), AI can detect cancer either.\nAS WSI is too big to fit into modern CNN architectures, it is divided into thousand of patches.\nAlso, there are only about 1000 WSI labels per dataset which easily provokes an over-fitting problem.\nOur lab focuses on multiple instance learning, where only slide-level labels are given.\nWe are trying to make pseudo-WSI labels by using information between patches. Furthermore, we are interested in self-supervised learning to extract adequate features for WSI.\n"}];function b(e,a,n){const t=e.slice();return t[0]=a[n],t}function w(e){let a,n,f,v,y,b,w,I,k,W,S=e[0].name+"",M=e[0].description+"";return{c(){a=t("div"),n=t("h2"),f=s(S),v=i(),y=t("p"),b=s(M),w=i(),I=t("img"),W=i(),this.h()},l(e){a=r(e,"DIV",{});var t=l(a);n=r(t,"H2",{class:!0});var s=l(n);f=o(s,S),s.forEach(c),v=d(t),y=r(t,"P",{class:!0});var i=l(y);b=o(i,M),i.forEach(c),w=d(t),I=r(t,"IMG",{src:!0,alt:!0,class:!0}),W=d(t),t.forEach(c),this.h()},h(){h(n,"class","svelte-18ll25p"),h(y,"class","svelte-18ll25p"),m(I.src,k=e[0].image||"image/dummy_wide.svg")||h(I,"src",k),h(I,"alt","..."),h(I,"class","svelte-18ll25p")},m(e,t){g(e,a,t),u(a,n),u(n,f),u(a,v),u(a,y),u(y,b),u(a,w),u(a,I),u(a,W)},p:p,d(e){e&&c(a)}}}function I(e){let a,n,s,o=y,m=[];for(let a=0;a<o.length;a+=1)m[a]=w(b(e,o,a));return{c(){a=i(),n=t("main"),s=t("div");for(let e=0;e<m.length;e+=1)m[e].c();this.h()},l(e){f('[data-svelte="svelte-2sbtyy"]',document.head).forEach(c),a=d(e),n=r(e,"MAIN",{});var t=l(n);s=r(t,"DIV",{class:!0});var i=l(s);for(let e=0;e<m.length;e+=1)m[e].l(i);i.forEach(c),t.forEach(c),this.h()},h(){document.title="SIML - Research",h(s,"class","content svelte-18ll25p")},m(e,t){g(e,a,t),g(e,n,t),u(n,s);for(let e=0;e<m.length;e+=1)m[e].m(s,null)},p(e,[a]){if(0&a){let n;for(o=y,n=0;n<o.length;n+=1){const t=b(e,o,n);m[n]?m[n].p(t,a):(m[n]=w(t),m[n].c(),m[n].m(s,null))}for(;n<m.length;n+=1)m[n].d(1);m.length=o.length}},i:p,o:p,d(e){e&&c(a),e&&c(n),v(m,e)}}}class k extends e{constructor(e){super(),a(this,e,null,I,n,{})}}export{k as default};
