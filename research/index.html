<!doctype html> <html lang=en> <head> <meta charset=utf-8> <meta content="width=device-width,initial-scale=1" name=viewport> <meta content=#004191 name=theme-color> <base href=/ > <link href=fonts.css rel=stylesheet> <link href=manifest.json rel=manifest> <link href=favicon.png rel=icon type=image/png> <link href=https://cdn.jsdelivr.net/npm/bootstrap-icons@1.4.0/font/bootstrap-icons.css rel=stylesheet> <link href=client/client-6a7065fa.css rel=stylesheet><link href=client/research-c54fbfbb.css rel=stylesheet> <title>SIML - Research</title> <link href=/client/client.58ce82e9.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/client-6a7065fa.css rel=preload as=style><link href=/client/research.d78d9916.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/inject_styles.803b7e80.js rel=modulepreload as=script crossorigin=use-credentials><link href=/client/research-c54fbfbb.css rel=preload as=style></head> <body id=sapper> <header class=svelte-10v0hvd><div class="svelte-10v0hvd content"><a class="svelte-10v0hvd brand" href=/ >SIML</a> <nav class=svelte-10v0hvd><a class=svelte-10v0hvd href=.>home</a> <a class="svelte-10v0hvd selected" href=research>research</a> <a class=svelte-10v0hvd href=publication>publication</a> <a class=svelte-10v0hvd href=people>people</a></nav></div></header> <main><div class="svelte-18ll25p content"><div><h2 class=svelte-18ll25p>Bayesian Deep Learning</h2> <p class=svelte-18ll25p>Modern deep neural networks are typically overparameterized and thus under-specified by the available data. In other words, deep neural networks often contain multiple solutions which can express hypotheses describing the data. While the classical training of deep neural networks aims to find a single solution, the Bayesian approach considers multiple possible solutions by performing marginalization. We are studying various sub-fields involving deep neural networks from the Bayesian perspective. </p> <img alt=... class=svelte-18ll25p src=image/research/bayesian.png> </div><div><h2 class=svelte-18ll25p>Diffusion</h2> <p class=svelte-18ll25p>Diffusion probabilistic models, or score-based generative models, are a class of generative models that have been achieving the state-of-the-art image generating quality, beating existing generative models such as GANs and variational autoencoders. Diffusion model recover the data distribution from a simple and tractable distribution such as normal, by learning the score function to reverse the diffusion process from the data to noise distributions. Our group is interested in both theoretical and applications of the diffusion models, such as the fast generation of high-quality samples and the downstream tasks involving the diffusion model such as adversarial robustness, few-shot learning, and the text-to-image generation. </p> <img alt=... class=svelte-18ll25p src=image/research/diffusion.png> </div><div><h2 class=svelte-18ll25p>Meta-Learning</h2> <p class=svelte-18ll25p>Meta-learning refers to algorithms that learn how to learn; more broadly, any algorithm that uses meta-knowledge to facilitate other learning tasks is an instance of meta-learning. Unlike hand-designed learning algorithms, meta-learned algorithms can directly leverage common structure or inherent knowledge extracted from multiple related tasks. This is essential for human-like AI capabilities such as continuously learning or processing multimodal data. In our lab, we are interested in the fundamentals of meta-learning and its applications. Specifically, we develop general meta-learning algorithms that learn meta-knowledge under real-world constraints, such as in settings with limited data. We also formulate domain-specific meta-learning methods for problem settings such as domain generalization, generative modeling, and Bayesian learning. </p> <img alt=... class=svelte-18ll25p src=image/research/meta-learning.png> </div><div><h2 class=svelte-18ll25p>Healthcare</h2> <p class=svelte-18ll25p>Detecting cancer was doctors' exclusive work before. Nowadays, thanks to the development of WSI(whole slide image), AI can detect cancer either. AS WSI is too big to fit into modern CNN architectures, it is divided into thousand of patches. Also, there are only about 1000 WSI labels per dataset which easily provokes an over-fitting problem. Our lab focuses on multiple instance learning, where only slide-level labels are given. We are trying to make pseudo-WSI labels by using information between patches. Furthermore, we are interested in self-supervised learning to extract adequate features for WSI. We are also studying a reliable medical classification model based on multimodal data (MRI, natural language, omics, etc.) by applying confidence estimation through Bayesian deep learning and interpretability using explainable AI techniques. </p> <img alt=... class=svelte-18ll25p src=image/research/healthcare.png> </div></div></main> <footer class=svelte-20p8do><div class="svelte-20p8do content"><p class="svelte-20p8do justify-left"><i class="bi bi-geo-alt"></i> <a class=svelte-20p8do href=https://goo.gl/maps/mga73qU9oT8Bhz8D6 target=_blank>KAIST N5, Room 2225 </a></div></footer> <script>__SAPPER__={baseUrl:"",preloaded:[void 0,{}]};if('serviceWorker' in navigator)navigator.serviceWorker.register('/service-worker.js');var s=document.createElement("script");try{new Function("if(0)import('')")();s.src="/client/client.58ce82e9.js";s.type="module";s.crossOrigin="use-credentials";}catch(e){s.src="/client/shimport@2.0.5.js";s.setAttribute("data-main","/client/client.58ce82e9.js")}document.head.appendChild(s)</script> <script src=bootstrap.bundle.min.js></script> 